---
layout: pos
title:  "EigenValue Decomposition"
image:  /images/SVD-img1.png
image1: /images/SVD-img2.png
vid: /images/SVD.mp4
toc: true
---

## Eigenvalue and Eigenvectors

* Eigenvalue problem of $m \times m$ matrix $\mathbf{A}$ is


$$\mathbf{A} \mathbf{x} = \lambda \mathbf{x}$$

with eigenvalues $\lambda$ and eigenvectors $\mathbf{x}$ (nonzero)

* The set of all the eigenvalues of $\mathbf{A}$ is the spectrum of $\mathbf{A}$

* Eigenvalue are generally used where a matrix is to be compounded iteratively

* Eigenvalues are useful for algorithmic and physical reasons
  * Algorithmically, eigenvalue analysis can reduce a coupled system to a
collection of scalar problems
  * Physically, eigenvalue analysis can be used to study resonance of
musical instruments and stability of physical systems


## Eigenvalue Decomposition
*  Eigenvalue decomposition of $\mathbf{A}$ is

$$\mathbf{A} = \mathbf{X} \Lambda \mathbf{X} ^{-1} \quad \text{or} \quad \mathbf{A} \mathbf{X} = \mathbf{X} \Lambda$$

with eigenvectors $\mathbf{x}$ i as columns of $\mathbf{X}$ and eigenvalues $\lambda_i$ along
diagonal of $\Lambda$. Alternatively,

$$\mathbf{A} \mathbf{x}_i = \lambda_i \mathbf{x}_i$$

*  Eigenvalue decomposition is change of basis to "eigenvector
coordinates"

$$\mathbf{A} \mathbf{x}  = \mathbf{b}  \rightarrow (\mathbf{X} \mathbf{b}^{-1}) =  \Lambda (\mathbf{X}^{-1} \mathbf{x})$$

*  Note that eigenvalue decomposition may not exist

*  Question: How does eigenvalue decomposition differ from SVD?

## Geometric Multiplicity

*  Eigenvectors corresponding to a single eigenvalue $\lambda$ form an eigenspace $E_\lambda \subseteq  \mathbb{C}^{m \times m}$

*  Eigenspace is invariant in that $\mathbf{A} E_\lambda \subseteq  E_\lambda$

*  Dimension of $E_\lambda $ is the maximum number of linearly independent eigenvectors that can be found

*  Geometric multiplicity of $\lambda$ is dimension of $E_\lambda$ , i.e., dim(null($\mathbf{A} - \lambda \mathbf{I}$ ))


## Algebraic Multiplicity
*  The characteristic polynomial of A is degree m polynomial

$$p_\mathbf{A} (z) = det(z \mathbf{I} - \mathbf{A} )  = (z -\lambda_1 )(z -\lambda_2 ) \cdots (z - \lambda_m )$$

which is monic in that coefficient of $z^m$ is $1$

*  $\lambda$ is eigenvalue of $\mathbf{A}$ iff $p_\mathbf{A} (\lambda) = 0$

    *  If $\lambda$ is eigenvalue, then by definition, $\lambda \mathbf{x} - \mathbf{A} \mathbf{x} = (\lambda \mathbf{I} - \mathbf{A}) \mathbf{x} = 0$, so
$(\lambda \mathbf{I} - \mathbf{A})$ is singular and its determinant is $0$

*  Algebraic multiplicity of $\lambda$ is its multiplicity as a root of
$p_\mathbf{A}$

*  Any matrix $\mathbf{A}$ has $m$ eigenvalues, counted with algebraic multiplicity

*  Question: What are the eigenvalues of a triangular matrix?

*  Question: How are geometric multiplicity and algebraic multiplicity
related?

## Similarity Transformations

* The map $\mathbf{A} \rightarrow \mathbf{Y}^{-1} \mathbf{A} \mathbf{Y}$ is a similarity transformation of $\mathbf{A}$ for any nonsingular $\mathbf{Y} \in \mathbb{C}^{m \times m}$

* $\mathbf{A}$ and $\mathbf{B}$ are similar if there is similarity transformation $\mathbf{B} = \mathbf{Y}^{-1} \mathbf{A} \mathbf{Y}$


If $\mathbf{Y}$ is nonsingular, then $\mathbf{A}$ and $\mathbf{Y}^{-1} \mathbf{A} \mathbf{Y}$ have the same characteristic
polynomials, eigenvalues, and algebraic and geometric multiplicities.


1. For characteristic polynomial:
$$det(z \mathbf{I} - \mathbf{Y}^{-1} \mathbf{A} \mathbf{Y}) = det(\mathbf{Y}^{-1} (z \mathbf{I} - \mathbf{A}) \mathbf{Y} ) = det(z \mathbf{I} - \mathbf{A})$$
so algebraic multiplicities remain the same

2. If $\mathbf{x} \in \mathbf{E}_\lambda$ for $\mathbf{A}$, then $\mathbf{Y}^{-1} \mathbf{x}$ is in eigenspace of $\mathbf{Y}^{-1}\mathbf{A} \mathbf{Y}$ corresponding
to $\lambda$, and vice versa, so geometric multiplicities remain the same
\end{enumerate}

## Algebraic Multiplicity â‰¥ Geometric Multiplicity

*  Let $n$ be be geometric multiplicity of $\lambda$ for $\mathbf{A}$. Let $\hat{\mathbf{V}} \in \mathbb{C}^{m \times n}$

constitute of orthonormal basis of the $\mathbf{E}_{\lambda}$
*  Extend $\hat{\mathbf{V}}$ to unitary $\mathbf{V} = [ \hat{\mathbf{V}} , \tilde{\mathbf{V}} ] \in \mathbb{C}^{m \times m}$ and form

$$\mathbf{B} = \mathbf{V}^* \mathbf{A} \mathbf{V} = \begin{bmatrix}
\hat{\mathbf{V}}^* \mathbf{A} \hat{\mathbf{V}}		& \hat{\mathbf{V}}^* \mathbf{A} \tilde{\mathbf{V}}\\
\tilde{\mathbf{V}}^* \mathbf{A} \hat{\mathbf{V}}	&\tilde{\mathbf{V}}^* \mathbf{A} \tilde{\mathbf{V}}
\end{bmatrix}
=
\begin{bmatrix}
\lambda \mathbf{I} 	&\mathbf{C} \\
0							& \mathbf{D}
\end{bmatrix}$$
<br/>
*  det($z \mathbf{I} - \mathbf{B}$) = det($z \mathbf{I} - \lambda \mathbf{I}$ )det($z \mathbf{I} - \lambda \mathbf{D}$) = $(z - \lambda)^n$ det$(z \mathbf{I} - \lambda \mathbf{D})$, so
the algebraic multiplicity of $\lambda$ as an eigenvalue of $\mathbf{B}$ is $\ge n$


*  $\mathbf{A}$ and $\mathbf{B}$ are similar, so the algebraic multiplicity of $\lambda$ as an eigenvalue
of $\mathbf{A}$ is at least $\ge n$

*  Examples:
$$
\mathbf{A} =
\begin{bmatrix}
2 & &\\
&2 & \\
&	&2
\end{bmatrix}
, \mathbf{B} =  
\begin{bmatrix}
2 &1 &\\
&2 &1 \\
&	&2
\end{bmatrix}
$$
Their characteristic polynomial is $(z - 2)^3$ , so algebraic multiplicity of
$\lambda = 2$ is $3$. But geometric multiplicity of $\mathbf{A}$ is $3$ and that of $\mathbf{B}$ is 1.


## Defective and Diagonalizable Matrices

item An eigenvalue of a matrix is defective if its algebraic multiplicity $>$ its
geometric multiplicity
*  A matrix is defective if it has a defective eigenvalue. Otherwise, it is
called nondefective.

An $m \times m$ matrix $\mathbf{A}$ is nondefective iff it has an eigenvalue decomposition
$\mathbf{A} = \mathbf{X} \Lambda \mathbf{X}^{-1}$.


*  ($\Leftarrow$) $\Lambda$ is nondefective, and $\mathbf{A}$ is similar to $\Lambda$, so $\mathbf{A}$ is nondefective.

*  ($\Rightarrow$) A nondefective matrix has m linearly independent eigenvectors.
Take them as columns of $\mathbf{X}$ to obtain $\mathbf{A} = \mathbf{X} \Lambda \mathbf{X}^{-1}$.

*  Nondefective matrices are therefore also said to be diagonalizable.


## Determinant and Trace

*  Determinant of $\mathbf{A}$ is det($\mathbf{A}$) = $\Pi_ {j=1}^m \lambda_j$, because

$$det(\mathbf{A}) = (-1)^m det(- \mathbf{A}) = (-1)^m p_{\mathbf{A}} (0) = \Pi_{j=1}^m \lambda_j$$

*  Trace of $\mathbf{A}$ is tr($\mathbf{A}$) = $\sum^m_{j=1} \lambda_j$, since

$$
p_\mathbf{A} (z) = det( z \mathbf{I} - \mathbf{A} ) = z^m - \sum_{j=1}^m a_{jj} z^{m-1} + O(z^{m-2})
$$
$$
p_\mathbf{A} (z) = \Pi_{j=1}^m( z - \lambda_j ) = z^m - \sum_{j=1}^m \lambda_{j} z^{m-1} + O(z^{m-2})
$$

*  Question: Are these results valid for defective or nondefective
matrices?
